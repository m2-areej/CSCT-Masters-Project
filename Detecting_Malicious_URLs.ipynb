{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fef96e9",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8fef96e9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "!pip install validators==0.20.0\n",
        "import validators\n",
        "import os.path\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the Dataset\n",
        "#df = pd.read_csv('../CSCT Masters Project/Datasets I Used/List of URLs.csv')\n",
        "data = pd.read_csv('List of URLs.csv')\n",
        "#data.head()\n",
        "print(data.shape)\n",
        "data.type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zm0QjwqYfr7c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zm0QjwqYfr7c"
      },
      "outputs": [],
      "source": [
        "#count of missing values in each column\n",
        "\n",
        "missing = data.isnull().sum()\n",
        "print(f\"Number of missing values: {missing}\")\n",
        "\n",
        "\n",
        "before_duplicates = data.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {before_duplicates}\")\n",
        "df = data.drop_duplicates()\n",
        "after_duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows after removing duplicates: {after_duplicates}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EzCYcWGuIUTZ",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EzCYcWGuIUTZ"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "df.type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851e2bc5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "851e2bc5"
      },
      "outputs": [],
      "source": [
        "df['length of url'] = df['url'].apply(lambda i: len(str(i)))\n",
        "\n",
        "def having_ip_address(url):\n",
        "  return 1 if validators.ip_address.ipv4(url) or validators.ip_address.ipv6(url) else 0\n",
        "\n",
        "df['use of ip'] = df['url'].apply(lambda i: having_ip_address(i))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66071de",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c66071de"
      },
      "outputs": [],
      "source": [
        "def use_of_hostname(url):\n",
        "    hostname = urlparse(url).hostname\n",
        "    if hostname is None:  # Handle the case when hostname is None\n",
        "        return 0\n",
        "    return 1 if hostname in url else 0\n",
        "\n",
        "df['use of hostname'] = df['url'].apply(use_of_hostname)\n",
        "df['length of hostname'] = df['url'].apply(lambda i: len(urlparse(i).netloc))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MssDFAKVTYXr",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MssDFAKVTYXr"
      },
      "outputs": [],
      "source": [
        "def count_of_dir(url):\n",
        "    urldir = urlparse(url).path\n",
        "    return urldir.count('/')\n",
        "df['count of /'] = df['url'].apply(lambda i: no_of_dir(i))\n",
        "\n",
        "def count_of_SchemeSeparator(url):\n",
        "    urldir = urlparse(url).path\n",
        "    return urldir.count('//')\n",
        "df['count of //'] = df['url'].apply(lambda i: no_of_SchemeSeparator(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hCbSvj2iGwjD",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hCbSvj2iGwjD"
      },
      "outputs": [],
      "source": [
        "# Length of First Directory\n",
        "def fd_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    path_parts = parsed_url.path.split('/')\n",
        "    if len(path_parts) > 1:\n",
        "        return len(path_parts[1])\n",
        "    else:\n",
        "        return 0\n",
        "df['length of first directory'] = df['url'].apply(fd_length)\n",
        "\n",
        "# Length of Top Level Domain\n",
        "def tld_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    return len(parsed_url.netloc)\n",
        "df['length of top level domain'] = df['url'].apply(tld_length)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fVOHcIa7Fg63",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fVOHcIa7Fg63"
      },
      "outputs": [],
      "source": [
        "def count_of_subdomains(url):\n",
        "  parsed_url = urlparse(url)\n",
        "  # Handling the case where hostname is None\n",
        "  if parsed_url.hostname is None:\n",
        "    return 0  # return 0 when a url is missing hostname\n",
        "  subdomains = parsed_url.hostname.split('.')\n",
        "  return len(subdomains) - 2\n",
        "\n",
        "df['count of subdomains'] = df['url'].apply(count_of_subdomains)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SRmbx4uVGK2s",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SRmbx4uVGK2s"
      },
      "outputs": [],
      "source": [
        "# checking whether a url shortening service has been used in the url or not\n",
        "\n",
        "shorteners = [\n",
        "    \"bit.ly\", \"goo.gl\", \"shorte.st\", \"go2l.ink\", \"x.co\", \"ow.ly\", \"t.co\",\n",
        "    \"tinyurl\", \"tr.im\", \"is.gd\", \"cli.gs\", \"yfrog.com\", \"migre.me\",\n",
        "    \"ff.im\", \"tiny.cc\", \"url4.eu\", \"twit.ac\", \"su.pr\", \"twurl.nl\",\n",
        "    \"snipurl.com\", \"short.to\", \"BudURL.com\", \"ping.fm\", \"post.ly\",\n",
        "    \"Just.as\", \"bkite.com\", \"snipr.com\", \"fic.kr\", \"loopt.us\",\n",
        "    \"doiop.com\", \"short.ie\", \"kl.am\", \"wp.me\", \"rubyurl.com\", \"om.ly\",\n",
        "    \"to.ly\", \"bit.do\", \"t.co\", \"lnkd.in\", \"db.tt\", \"qr.ae\", \"adf.ly\",\n",
        "    \"goo.gl\", \"bitly.com\", \"cur.lv\", \"tinyurl.com\", \"ow.ly\", \"bit.ly\",\n",
        "    \"ity.im\", \"q.gs\", \"is.gd\", \"po.st\", \"bc.vc\", \"twitthis.com\", \"u.to\",\n",
        "    \"j.mp\", \"buzurl.com\", \"cutt.us\", \"u.bb\", \"yourls.org\", \"x.co\",\n",
        "    \"prettylinkpro.com\", \"scrnch.me\", \"filoops.info\", \"vzturl.com\",\n",
        "    \"qr.net\", \"1url.com\", \"tweez.me\", \"v.gd\", \"tr.im\", \"link.zip.net\"\n",
        "]\n",
        "\n",
        "def shortening_service(url):\n",
        "    for shortener in shorteners:\n",
        "        if shortener in url:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "df['use of url shortner'] = df['url'].apply(lambda i: shortening_service(i))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fMCS1wGTGtEq",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fMCS1wGTGtEq"
      },
      "outputs": [],
      "source": [
        "df['count of https'] = df['url'].apply(lambda i : i.count('https'))\n",
        "df['count of http'] = df['url'].apply(lambda i : i.count('http'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D05bIIreGtxu",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D05bIIreGtxu"
      },
      "outputs": [],
      "source": [
        "# counting multiple special characters\n",
        "df['count of %'] = df['url'].apply(lambda i: i.count('%'))\n",
        "df['count of ?'] = df['url'].apply(lambda i: i.count('?'))\n",
        "df['count of -'] = df['url'].apply(lambda i: i.count('-'))\n",
        "df['count of ='] = df['url'].apply(lambda i: i.count('='))\n",
        "df['count of .'] = df['url'].apply(lambda i: i.count('.'))\n",
        "df['count of www'] = df['url'].apply(lambda i: i.count('www'))\n",
        "df['count of @'] = df['url'].apply(lambda i: i.count('@'))\n",
        "df['count of #'] = df['url'].apply(lambda i: i.count('#'))\n",
        "df['count of !'] = df['url'].apply(lambda i: i.count('!'))\n",
        "df['count of $'] = df['url'].apply(lambda i: i.count('$'))\n",
        "df['count of *'] = df['url'].apply(lambda i: i.count('*'))\n",
        "df['count of _'] = df['url'].apply(lambda i: i.count('_'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZmVwiW_zHuI5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZmVwiW_zHuI5"
      },
      "outputs": [],
      "source": [
        "df['count of numbers'] = df['url'].str.count('\\d')\n",
        "\n",
        "df['count of letters'] = df['url'].str.count('[a-zA-Z]')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ophNhmgvkdw4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ophNhmgvkdw4"
      },
      "outputs": [],
      "source": [
        "lb_make = LabelEncoder()\n",
        "df[\"type_code\"] = lb_make.fit_transform(df[\"type\"])\n",
        "print(df[\"type_code\"].value_counts())\n",
        "df.to_csv('my_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mSUzc5lpn3Cp",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mSUzc5lpn3Cp"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['type_code', 'url', 'type'], axis=1)  # Predictor variables - all columns except type_code, url, and type\n",
        "y = df['type_code']              # Target variable\n",
        "\n",
        "\n",
        "#print(\"\\nTarget variable (y):\")\n",
        "#print(y.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S_QUXQZioJKc",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S_QUXQZioJKc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sR9G4kTevCnu",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sR9G4kTevCnu"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(rf_classifier, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# Make predictions on the test set (assuming you have a separate test set)\n",
        "# Replace X_test with your actual test data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy on test set:\", accuracy)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NlBGHDamFpzT",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NlBGHDamFpzT"
      },
      "outputs": [],
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000) # Adjust hyperparameters as needed\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dzf5CaNkFx4e",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzf5CaNkFx4e",
        "outputId": "4fc46b23-310a-4e35-a6ac-1b86bc35eac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9515071163969585\n",
            "Cross-validation scores: [0.95238058 0.97126145 0.95065705 0.92556834 0.81294599]\n",
            "Average cross-validation score: 0.9225626827841683\n",
            "Confusion matrix:\n",
            " [[84530    65    16   893]\n",
            " [  115 18704    60   263]\n",
            " [   83   203  4114   307]\n",
            " [ 3227   655   331 14659]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     85504\n",
            "           1       0.95      0.98      0.96     19142\n",
            "           2       0.91      0.87      0.89      4707\n",
            "           3       0.91      0.78      0.84     18872\n",
            "\n",
            "    accuracy                           0.95    128225\n",
            "   macro avg       0.93      0.90      0.92    128225\n",
            "weighted avg       0.95      0.95      0.95    128225\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", scores.mean())\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8O9WNUFrvxhG",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8O9WNUFrvxhG",
        "outputId": "7ca0821a-9cf4-42f4-91bd-719d92d9cef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7829830376291674\n",
            "Cross-validation scores: [0.78309222 0.78032365 0.82179762 0.77971534 0.73140963]\n",
            "Average cross-validation score: 0.7792676935075062\n",
            "Confusion matrix:\n",
            " [[78845  5198   735   726]\n",
            " [   18 19069    28    27]\n",
            " [  252  3021  1396    38]\n",
            " [13865  2961   958  1088]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88     85504\n",
            "           1       0.63      1.00      0.77     19142\n",
            "           2       0.45      0.30      0.36      4707\n",
            "           3       0.58      0.06      0.10     18872\n",
            "\n",
            "    accuracy                           0.78    128225\n",
            "   macro avg       0.63      0.57      0.53    128225\n",
            "weighted avg       0.76      0.78      0.73    128225\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "scores = cross_val_score(nb_classifier, X, y, cv=5)\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", scores.mean())\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def random_url():\n",
        "    domain = ''.join(random.choices(string.ascii_lowercase, k=8)) + \".com\"\n",
        "    path = ''.join(random.choices(string.ascii_lowercase + string.digits, k=10))\n",
        "    return f\"http://{domain}/{path}\"\n",
        "\n",
        "print(random_url())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OcynC3C5zzD",
        "outputId": "d0d678f7-d53f-44b7-aaf6-87edfecc1dc3"
      },
      "id": "9OcynC3C5zzD",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://cpwkqhdj.com/7n88g7st7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ntrXjNIV4pKd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntrXjNIV4pKd",
        "outputId": "c53a3d16-d830-4761-cce9-9525677fa88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a URL: https://ods.od.nih.gov/factsheets/VitaminD-HealthProfessional/\n",
            "Random Forest Prediction: [3]\n",
            "Naive Bayes Prediction: [2]\n",
            "MLPClassifier Prediction: [3]\n"
          ]
        }
      ],
      "source": [
        "#new_url = random_url()\n",
        "new_url = input(\"Enter a URL: \")\n",
        "\n",
        "new_url_features = {\n",
        "    'length of url': len(new_url),\n",
        "    'use of ip': having_ip_address(new_url),\n",
        "    'use of hostname': use_of_hostname(new_url),\n",
        "    'length of hostname': len(urlparse(new_url).netloc),\n",
        "    'count of /': count_of_dir(new_url),\n",
        "    'count of //': count_of_SchemeSeparator(new_url),\n",
        "    'length of first directory': fd_length(new_url),\n",
        "    'length of top level domain': tld_length(new_url),\n",
        "    'count of subdomains': count_of_subdomains(new_url),\n",
        "    'use of url shortner': shortening_service(new_url),\n",
        "    'count of https': new_url.count('https'),\n",
        "    'count of http': new_url.count('http'),\n",
        "    'count of %': new_url.count('%'),\n",
        "    'count of ?': new_url.count('?'),\n",
        "    'count of -': new_url.count('-'),\n",
        "    'count of =': new_url.count('='),\n",
        "    'count of .': new_url.count('.'),\n",
        "    'count of www': new_url.count('www'),\n",
        "    'count of @': new_url.count('@'),\n",
        "    'count of #': new_url.count('#'),\n",
        "    'count of !': new_url.count('!'),\n",
        "    'count of $': new_url.count('$'),\n",
        "    'count of *': new_url.count('*'),\n",
        "    'count of _': new_url.count('_'),\n",
        "    'count of numbers': new_url.count('\\d'),\n",
        "    'count of letters': new_url.count('[a-zA-Z]')\n",
        "}\n",
        "\n",
        "# Create a DataFrame for the new URL\n",
        "new_url_df = pd.DataFrame([new_url_features])\n",
        "\n",
        "# RandomForest Prediction\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(new_url_df)\n",
        "\n",
        "# Interpret the prediction (0 for benign, 1 for malicious, etc.)\n",
        "print(\"Random Forest Prediction:\", prediction)\n",
        "\n",
        "# Naive Bayes prediction\n",
        "nb_prediction = nb_classifier.predict(new_url_df)\n",
        "print(\"Naive Bayes Prediction:\", nb_prediction)\n",
        "\n",
        "# MLPClassifier prediction\n",
        "mlp_prediction = clf.predict(new_url_df)\n",
        "print(\"MLPClassifier Prediction:\", mlp_prediction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}